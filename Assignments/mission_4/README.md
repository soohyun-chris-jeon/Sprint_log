# [스프린트 미션#4]은행 마케팅 데이터셋 분류 보고서
### 5팀 전수현
### 작성 일자: 2025/06/04

## 1. Introduction

본 보고서는 잘 알려진 `bank-additional-full.csv` 데이터셋을 활용하여 이진 분류 문제를 해결하기 위한 전처리, 모델링 및 평가 과정을 설명합니다. 목표는 다양한 고객 및 마케팅 속성 정보를 바탕으로 해당 고객이 정기예금에 가입할지 여부(`y`: yes/no)를 예측하는 것입니다. 여러 분류 모델과 앙상블 기법을 탐색하고, GridSearchCV를 통해 하이퍼파라미터 최적화를 수행했습니다.

---

## 2. Data pre-processing

### 2.1. 타겟 인코딩

* 타겟 열 `y`를 이진 값으로 변환하였습니다: `'yes' -> 1`, `'no' -> 0`

### 2.2. 상관관계 기반 피처 제거

* 수치형 변수에 대해 절대값 상관계수 행렬을 계산하였습니다.
* 상관계수가 `|0.7|` 이상인 피처는 중복 가능성이 있어 제거 대상으로 지정했습니다.
* 단, `euribor3m` 변수는 높은 예측력을 고려하여 유지했습니다.
* 또한, `duration` 변수는 결과를 누설할 수 있어 제거했습니다.

### 2.3. 학습-테스트 데이터 분리

* 전체 데이터를 학습용(80%)과 테스트용(20%)으로 분리하였고,
* 타겟 변수의 클래스 불균형을 고려하여 `stratify` 옵션을 적용했습니다.

### 2.4. 전처리 파이프라인 구성

* **수치형 변수**: `StandardScaler`를 사용하여 표준화
* **범주형 변수**: `OneHotEncoder(handle_unknown="ignore")`를 사용하여 원-핫 인코딩

---

## 3. 모델 학습 및 평가

파이프라인 기반 접근 방식을 통해 다음 모델들을 학습하고 평가했습니다:

### 3.1. 개별 모델

* **결정 트리 분류기 (Decision Tree)**
* **랜덤 포레스트 분류기 (Random Forest)**
* **그래디언트 부스팅 분류기 (Gradient Boosting)**
* **히스토그램 기반 그래디언트 부스팅 분류기 (Hist Gradient Boosting)**

각 모델은 파이프라인을 통해 학습되었으며, 테스트 데이터에서의 예측 결과에 대해 정밀도, 재현율, F1 점수를 포함하는 `classification_report`로 평가하였습니다.

### 3.2. 앙상블 모델

* **VotingClassifier**를 사용하여 `랜덤포레스트`, `그래디언트 부스팅`, `결정 트리` 모델을 결합
* 소프트 보팅(확률 기반)을 통해 예측 성능을 높임

---

## 4. 하이퍼파라미터 튜닝

`Random Forest` 모델에 대해 아래와 같은 파라미터 그리드를 사용하여 GridSearchCV를 수행하였습니다:

* `n_estimators`: \[100, 300]
* `max_depth`: \[None, 10, 20]
* `min_samples_split`: \[2, 5]

평가 지표: **F1-score** (5-폴드 교차검증)

**최적 파라미터 예시:**

* `n_estimators=300`, `max_depth=None`, `min_samples_split=2`

최적 모델은 테스트 세트에서 추가 평가를 진행하였습니다.

---

## 5. 최종 결과 및 결론

테스트 데이터 평가 기준으로:

* **GridSearch로 튜닝된 Random Forest 모델**이 가장 우수한 F1-score를 기록하였습니다.
* Voting 앙상블 모델도 준수한 성능을 보였으며, 다양한 모델의 예측력을 종합하여 안정적인 결과를 도출했습니다.
* `Gradient Boosting` 및 `HistGradientBoosting` 모델도 경쟁력 있는 성능을 보였으나, 튜닝된 Random Forest보다 약간 낮은 성능을 보였습니다.

### 최종 추천 모델

> **RandomForestClassifier (튜닝된 파라미터 포함)**: 높은 F1-score, 일반화 능력, 해석 가능성 등을 고려했을 때 가장 적합한 모델로 판단됩니다.

---

## 6. 향후 개선 방향

* SHAP 또는 permutation importance를 활용한 모델 해석 시도
* 클래스 불균형이 더 클 경우, SMOTE 또는 class\_weight 조정 적용
* 추가적인 피처 엔지니어링 또는 차원 축소 기법 적용
* AutoML 프레임워크 또는 다양한 앙상블 전략 탐색



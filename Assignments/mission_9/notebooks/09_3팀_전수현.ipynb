{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3652fe3",
   "metadata": {},
   "source": [
    "## 0. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c49bb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soohyun/miniconda3/envs/JSH/lib/python3.13/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# STEP 0: Import Libraries\n",
    "# ====================================================================\n",
    "# 과제에 사용할 library들을 import\n",
    "\n",
    "# 시스템 및 입출력 관련\n",
    "import os  # 디렉토리, 파일 경로 조작 등\n",
    "from PIL import Image  # 이미지 열기 및 처리 (Pillow)\n",
    "from tqdm import tqdm  # 반복문의 진행 상태 시각화\n",
    "from pathlib import Path  # payhon path\n",
    "\n",
    "\n",
    "# 시각화 도구\n",
    "import matplotlib.pyplot as plt  # 기본 시각화 라이브러리\n",
    "import seaborn as sns  # 고급 시각화 (히트맵, 스타일 등)\n",
    "\n",
    "# 이미지 처리\n",
    "import cv2  # OpenCV - 고급 이미지/비디오 처리\n",
    "\n",
    "# 수치 연산\n",
    "import numpy as np  # 배열, 벡터 계산 등\n",
    "\n",
    "# PyTorch 기본 구성\n",
    "import torch  # 텐서, 연산 등\n",
    "import torch.nn as nn  # 모델 정의 (layer, loss 등)\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim  # Optimizer (SGD, Adam 등)\n",
    "\n",
    "# PyTorch 데이터 처리\n",
    "from torch.utils.data import Dataset, DataLoader  # 커스텀 데이터셋, 배치 로딩\n",
    "\n",
    "# PyTorch 이미지 전처리\n",
    "import torchvision\n",
    "from torchvision import transforms  # 기본 이미지 transform\n",
    "from torchvision import datasets  # torchvision 내장 데이터셋\n",
    "import torchvision.models as models\n",
    "\n",
    "from torchvision.transforms import v2  # torchvision v2 transforms (최신 API)\n",
    "\n",
    "# 싸이킷런 평가 지표\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# 싸이킷런 데이터 나누기\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 통계 tool\n",
    "import pandas as pd\n",
    "\n",
    "# 실험 추적 및 하이퍼파라미터 관리\n",
    "import wandb  # Weights & Biases - 실험 로깅, 시각화, 하이퍼파라미터 튜닝\n",
    "\n",
    "# Garbage Collector 모듈\n",
    "import gc\n",
    "\n",
    "# Data Augmentation 패키지: Albumentations\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938bfea0",
   "metadata": {},
   "source": [
    "## 1. Set configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fab778e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# STEP 1: Configuration 설정\n",
    "# ====================================================================\n",
    "# 하이퍼파라미터 및 경로 등 실험에 필요한 설정들을 모아둠\n",
    "# 실험 추적 및 재현성을 위해 모든 값은 여기에서 수정하고자 함\n",
    "\n",
    "# 디바이스 설정\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 주요 하이퍼파라미터\n",
    "LEARNING_RATE = 1e-4  # 학습률 (optimizer용)\n",
    "BATCH_SIZE = 16  # 배치 크기\n",
    "NUM_EPOCHS = 100  # 학습 epoch 수\n",
    "SEED = 42  # 재현성을 위한 random seed\n",
    "\n",
    "# 데이터 경로 설정\n",
    "# DATA_ROOT = path\n",
    "# train_dir = os.path.join(DATA_ROOT, \"train\")\n",
    "# val_dir = os.path.join(DATA_ROOT, \"val\")\n",
    "# test_dir = os.path.join(DATA_ROOT, \"test\")\n",
    "\n",
    "# 모델 설정\n",
    "MODEL_NAME = \"PROJECT1_baseline\"  # 또는 \"EfficientNet\", 등등\n",
    "USE_PRETRAINED = True  # torchvision 모델 사용 여부\n",
    "\n",
    "# 학습 고도화 설정 (Optional)\n",
    "USE_SCHEDULER = True  # Learning rate scheduler 사용 여부\n",
    "EARLY_STOPPING = True  # Early stopping 적용 여부\n",
    "AUGMENTATION = True  # 데이터 증강 사용 여부\n",
    "\n",
    "# 실험 로깅용 설정\n",
    "USE_WANDB = True\n",
    "WANDB_PROJECT = \"cats-and-dogs-breeds-classification-oxford-dataset\"\n",
    "RUN_NAME = f\"{MODEL_NAME}_bs{BATCH_SIZE}_lr{LEARNING_RATE}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e29721",
   "metadata": {},
   "source": [
    "## 2. Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7af7cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.4M/26.4M [00:07<00:00, 3.77MB/s]\n",
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 112kB/s]\n",
      "100%|██████████| 4.42M/4.42M [00:02<00:00, 1.67MB/s]\n",
      "100%|██████████| 5.15k/5.15k [00:00<00:00, 9.31MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'T-shirt/top',\n",
       " 1: 'Trouser',\n",
       " 2: 'Pullover',\n",
       " 3: 'Dress',\n",
       " 4: 'Coat',\n",
       " 5: 'Sandal',\n",
       " 6: 'Shirt',\n",
       " 7: 'Sneaker',\n",
       " 8: 'Bag',\n",
       " 9: 'Ankle boot'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋 및 DataLoader 설정\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),  # [-1, 1] 범위로 정규화\n",
    "    ]\n",
    ")\n",
    "train_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root=\"../data\", train=True, download=True, transform=transform\n",
    ")\n",
    "test_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root=\"../data\", train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 클래스 이름 (FashionMNIST 클래스)\n",
    "idx_to_class = {i: class_name for i, class_name in enumerate(train_dataset.classes)}\n",
    "idx_to_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be61a8d7",
   "metadata": {},
   "source": [
    "## 3. Model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a26c3d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b21bc158",
   "metadata": {},
   "source": [
    "## 4. Train and Evaluate models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b287fe",
   "metadata": {},
   "source": [
    "## 5. Train and Evaluate a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f55c038",
   "metadata": {},
   "source": [
    "## 6. Results & Disscussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e4ed03",
   "metadata": {},
   "source": [
    "## 7. Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JSH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
